{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Sandbox_ de NLP con spaCy\n",
    "Este _notebook_ les brinda un entorno de prueba para explorar algunas de las capacidades de spaCy como plataforma de _Natural Language Processing_. La idea es que puedan interactuar directamente con este tipo de tecnología para que se vayan con una idea más concreta. \n",
    "\n",
    "**Importante:** Recuerden que esto es una demo, puede haber algunas formas más complejas de trabajar y también puede haber desarrollos futuros que mejoren por sobre lo que pueden explorar en este _notebook_.\n",
    "\n",
    "---\n",
    "\n",
    "### Instrucciones previas\n",
    "Para poder ejecutar este código, vamos a asegurarnos primero que Google Colab tiene instalado spaCy y vamos a requerirle que descargue el modelo español de tamaño mediano (pueden consultar instrucciones de instalación de spaCy [en este link](https://spacy.io/usage)).\n",
    "\n",
    "Es necesario entonces ejecutar la siguiente celda de código (Shift+Enter cuando la celda se encuentra seleccionada, o el ícono de _play_ a la izquierda de la celda). Si la celda se ejecuta correctamente podemos ignorar la salida. Si no cambian nada de esta celda, no debería haber problemas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy -U\n",
    "!python -m spacy download es_core_news_md\n",
    "import spacy\n",
    "import warnings\n",
    "\n",
    "\n",
    "from spacy import displacy\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "nlp = spacy.load(\"es_core_news_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis básico\n",
    "Una vez que tenemos listo el modelo de NLP, para procesar un texto tenemos que generar un \"documento\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"\"\"\n",
    "Podemos darle a spaCy un montón de texto. Recuerden que para que Python pueda interpretar\n",
    "correctamente el texto, tienen que escribirlo entre las triples comillas dobles. Es decir,\n",
    "mientras no eliminen la primer y última línea de esta celda, todo debería funcionar correctamente.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que tenemos el \"objeto documento\", podemos hacerle consultas. Por ejemplo, podemos ver cuántas entidades ha podido detectar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entidad in doc.ents:\n",
    "    print(f\"Entidad: '{entidad}' de tipo {entidad.label_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O podemos verificar, por ejemplo, cada uno de los verbos en la oración:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    if token.pos_ == \"VERB\":\n",
    "        print(f\"Verbo: {token}\")\n",
    "    if token.pos_ == \"AUX\":\n",
    "        print(f\"Aux. : {token}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis con `displacy`\n",
    "Esta forma de trabajar es un poco trabajosa y se presta más a un perfil de programación. Para ver de manera más gráfica el análisis que realiza spaCy podemos utilizar las funciones del módulo `displacy` que forman parte de la librería.\n",
    "\n",
    "Por ejemplo, partiendo el documento en oraciones, podemos ver el arbol de dependencias entre las palabras del texto analizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "displacy.render(list(doc.sents), style=\"dep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`displacy` también nos permite visualizar las entidades de manera más simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y con un poco de trabajo, también se puede utilizar `displacy` para ver cada palabra de acuerdo al _part of speech_ ([ver referencia online](https://universaldependencies.org/docs/u/pos/)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = []\n",
    "all_ents = set()\n",
    "\n",
    "for token in doc:\n",
    "    match = {}\n",
    "    match[\"start\"] = token.idx\n",
    "    match[\"end\"]   = token.idx + len(token)\n",
    "    match[\"label\"] = token.pos_\n",
    "    matches.append(match)\n",
    "    all_ents.add(token.pos_)\n",
    "    \n",
    "sentence = [{\n",
    "    \"text\": doc.text,\n",
    "    \"ents\": matches\n",
    "}]\n",
    "\n",
    "# acá definimos los colores para las etiquetas\n",
    "options = {\n",
    "    \"ents\": list(all_ents),\n",
    "    \"colors\": {\n",
    "        #\"ADP\": \"yellow\",\n",
    "        #\"VERB\": \"#0f0\",\n",
    "        #\"AUX\": \"#0a0\",\n",
    "    }\n",
    "}\n",
    "\n",
    "displacy.render(sentence, style=\"ent\", manual=True, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.3 64-bit",
   "language": "python",
   "name": "python36364bit6b3bb631f1854918a9d097d690ec0997"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
